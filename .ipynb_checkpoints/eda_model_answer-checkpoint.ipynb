{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a207638d-2d90-4a41-81e0-f86b35a174f9",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "1. Import packages\n",
    "2. Loading data with Pandas\n",
    "3. Descriptive statistics of data\n",
    "4. Data visualization\n",
    "5. Hypothesis investigation\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fa22a3-62fc-4ee9-ad3b-5e3fbc059bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Shows plots in jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plot style\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb5312-cbc0-4193-b84e-2c94455c9edf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Loading data with Pandas\n",
    "\n",
    "We need to load `client_data.csv` and `price_data.csv` into individual dataframes so that we can work with them in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6a4ae-2b8a-4152-b04f-0c998466fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = pd.read_csv('./client_data.csv')\n",
    "price_df = pd.read_csv('./price_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7aaab-7c26-40ca-8f63-cf2ef9541ce6",
   "metadata": {},
   "source": [
    "Let's look at the first 3 rows of both dataframes to see what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0d488-d3df-4819-a52b-e335c0674e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081f742-7967-457e-956f-94b8d4e6b46e",
   "metadata": {},
   "source": [
    "With the client data, we have a mix of numeric and categorical data, which we will need to transform before modelling later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654a02d-8cf3-4a18-903e-b4f7f95d8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e3f0d-1b6b-49fa-a48c-8d39ff77adf1",
   "metadata": {},
   "source": [
    "With the price data, it is purely numeric data but we can see a lot of zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c3948-41c0-4183-9118-dd665c58a93c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Descriptive statistics of data\n",
    "\n",
    "### Data types\n",
    "\n",
    "It is useful to first understand the data that you're dealing with along with the data types of each column. The data types may dictate how you transform and engineer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc75b07-c286-4852-bc33-e501782e67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f2628-351a-48ee-b8ba-88c54042af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d523f6-1a61-4645-814a-b78fb8a6a540",
   "metadata": {},
   "source": [
    "You can see that all of the `datetime` related columns are not currently in datetime format. We will need to convert these later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e80c5-ef07-47a7-908a-a081b3ebd09e",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "Now let's look at some statistics about the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3010c-ecaf-4b8a-bb87-93bb54cc0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf88b77-f1e3-4e7c-8b87-310d62e70a94",
   "metadata": {},
   "source": [
    "The describe method gives us a lot of information about the client data. The key point to take away from this is that we have highly skewed data, as exhibited by the percentile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b442e6-e186-42f9-b3c5-c5c15cd8c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a8879-c483-4464-9057-c70e6b150e53",
   "metadata": {},
   "source": [
    "Overall the price data looks good.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data visualization\n",
    "\n",
    "Now let's dive a bit deeper into the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350ea0a-dc45-43f5-a6b7-e5e816964419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_bars(dataframe, title_, size_=(18, 10), rot_=0, legend_=\"upper right\"):\n",
    "    \"\"\"\n",
    "    Plot stacked bars with annotations\n",
    "    \"\"\"\n",
    "    ax = dataframe.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        figsize=size_,\n",
    "        rot=rot_,\n",
    "        title=title_\n",
    "    )\n",
    "\n",
    "    # Annotate bars\n",
    "    annotate_stacked_bars(ax, textsize=14)\n",
    "    # Rename legend\n",
    "    plt.legend([\"Retention\", \"Churn\"], loc=legend_)\n",
    "    # Labels\n",
    "    plt.ylabel(\"Company base (%)\")\n",
    "    plt.show()\n",
    "\n",
    "def annotate_stacked_bars(ax, pad=0.99, colour=\"white\", textsize=13):\n",
    "    \"\"\"\n",
    "    Add value annotations to the bars\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over the plotted rectanges/bars\n",
    "    for p in ax.patches:\n",
    "        \n",
    "        # Calculate annotation\n",
    "        value = str(round(p.get_height(),1))\n",
    "        # If value is 0 do not annotate\n",
    "        if value == '0.0':\n",
    "            continue\n",
    "        ax.annotate(\n",
    "            value,\n",
    "            ((p.get_x()+ p.get_width()/2)*pad-0.05, (p.get_y()+p.get_height()/2)*pad),\n",
    "            color=colour,\n",
    "            size=textsize\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe9008",
   "metadata": {},
   "source": [
    "### Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea468a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = client_df[['id', 'churn']]\n",
    "churn.columns = ['Companies', 'churn']\n",
    "churn_total = churn.groupby(churn['churn']).count()\n",
    "churn_percentage = churn_total / churn_total.sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars(churn_percentage.transpose(), \"Churning status\", (5, 5), legend_=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e2a36",
   "metadata": {},
   "source": [
    "About 10% of the total customers have churned. (This sounds about right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca202c",
   "metadata": {},
   "source": [
    "### Sales channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9539908",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = client_df[['id', 'channel_sales', 'churn']]\n",
    "channel = channel.groupby([channel['channel_sales'], channel['churn']])['id'].count().unstack(level=1).fillna(0)\n",
    "channel_churn = (channel.div(channel.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars(channel_churn, 'Sales channel', rot_=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8f022",
   "metadata": {},
   "source": [
    "Interestingly, the churning customers are distributed over 5 different values for `channel_sales`. As well as this, the value of `MISSING` has a churn rate of 7.6%. `MISSING` indicates a missing value and was added by the team when they were cleaning the dataset. This feature could be an important feature when it comes to building our model.\n",
    "\n",
    "### Consumption\n",
    "\n",
    "Let's see the distribution of the consumption in the last year and month. Since the consumption data is univariate, let's use histograms to visualize their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = client_df[['id', 'cons_12m', 'cons_gas_12m', 'cons_last_month', 'imp_cons', 'has_gas', 'churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(dataframe, column, ax, bins_=50):\n",
    "    \"\"\"\n",
    "    Plot variable distirbution in a stacked histogram of churned or retained company\n",
    "    \"\"\"\n",
    "    # Create a temporal dataframe with the data to be plot\n",
    "    temp = pd.DataFrame({\"Retention\": dataframe[dataframe[\"churn\"]==0][column],\n",
    "    \"Churn\":dataframe[dataframe[\"churn\"]==1][column]})\n",
    "    # Plot the histogram\n",
    "    temp[[\"Retention\",\"Churn\"]].plot(kind='hist', bins=bins_, ax=ax, stacked=True)\n",
    "    # X-axis label\n",
    "    ax.set_xlabel(column)\n",
    "    # Change the x-axis to plain style\n",
    "    ax.ticklabel_format(style='plain', axis='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc098b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, figsize=(18, 25))\n",
    "\n",
    "plot_distribution(consumption, 'cons_12m', axs[0])\n",
    "plot_distribution(consumption[consumption['has_gas'] == 't'], 'cons_gas_12m', axs[1])\n",
    "plot_distribution(consumption, 'cons_last_month', axs[2])\n",
    "plot_distribution(consumption, 'imp_cons', axs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e575378",
   "metadata": {},
   "source": [
    "Clearly, the consumption data is highly positively skewed, presenting a very long right-tail towards the higher values of the distribution. The values on the higher and lower end of the distribution are likely to be outliers. We can use a standard plot to visualise the outliers in more detail. A boxplot is a standardized way of displaying the distribution based on a five number summary:\n",
    "- Minimum\n",
    "- First quartile (Q1)\n",
    "- Median\n",
    "- Third quartile (Q3)\n",
    "- Maximum\n",
    "\n",
    "It can reveal outliers and what their values are. It can also tell us if our data is symmetrical, how tightly our data is grouped and if/how our data is skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, figsize=(18,25))\n",
    "\n",
    "# Plot histogram\n",
    "sns.boxplot(consumption[\"cons_12m\"], ax=axs[0])\n",
    "sns.boxplot(consumption[consumption[\"has_gas\"] == \"t\"][\"cons_gas_12m\"], ax=axs[1])\n",
    "sns.boxplot(consumption[\"cons_last_month\"], ax=axs[2])\n",
    "sns.boxplot(consumption[\"imp_cons\"], ax=axs[3])\n",
    "\n",
    "# Remove scientific notation\n",
    "for ax in axs:\n",
    "    ax.ticklabel_format(style='plain', axis='x')\n",
    "    # Set x-axis limit\n",
    "    axs[0].set_xlim(-200000, 2000000)\n",
    "    axs[1].set_xlim(-200000, 2000000)\n",
    "    axs[2].set_xlim(-20000, 100000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54525b74",
   "metadata": {},
   "source": [
    "We will deal with skewness and outliers during feature engineering in the next exercise.\n",
    "\n",
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bff478",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = client_df[\n",
    "    [\"id\", \"forecast_cons_12m\",\n",
    "    \"forecast_cons_year\",\"forecast_discount_energy\",\"forecast_meter_rent_12m\",\n",
    "    \"forecast_price_energy_p1\",\"forecast_price_energy_p2\",\n",
    "    \"forecast_price_pow_p1\",\"churn\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=7, figsize=(18,50))\n",
    "\n",
    "# Plot histogram\n",
    "plot_distribution(client_df, \"forecast_cons_12m\", axs[0])\n",
    "plot_distribution(client_df, \"forecast_cons_year\", axs[1])\n",
    "plot_distribution(client_df, \"forecast_discount_energy\", axs[2])\n",
    "plot_distribution(client_df, \"forecast_meter_rent_12m\", axs[3])\n",
    "plot_distribution(client_df, \"forecast_price_energy_p1\", axs[4])\n",
    "plot_distribution(client_df, \"forecast_price_energy_p2\", axs[5])\n",
    "plot_distribution(client_df, \"forecast_price_pow_p1\", axs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9149879",
   "metadata": {},
   "source": [
    "Similarly to the consumption plots, we can observe that a lot of the variables are highly positively skewed, creating a very long tail for the higher values. We will make some transformations during the next exercise to correct for this skewness.\n",
    "\n",
    "### Contract type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_type = client_df[['id', 'has_gas', 'churn']]\n",
    "contract = contract_type.groupby([contract_type['churn'], contract_type['has_gas']])['id'].count().unstack(level=0)\n",
    "contract_percentage = (contract.div(contract.sum(axis=1), axis=0) * 100).sort_values(by=[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b797da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars(contract_percentage, 'Contract type (with gas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c4c54",
   "metadata": {},
   "source": [
    "### Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7457f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = client_df[['id', 'margin_gross_pow_ele', 'margin_net_pow_ele', 'net_margin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, figsize=(18,20))\n",
    "# Plot histogram\n",
    "sns.boxplot(margin[\"margin_gross_pow_ele\"], ax=axs[0])\n",
    "sns.boxplot(margin[\"margin_net_pow_ele\"],ax=axs[1])\n",
    "sns.boxplot(margin[\"net_margin\"], ax=axs[2])\n",
    "# Remove scientific notation\n",
    "axs[0].ticklabel_format(style='plain', axis='x')\n",
    "axs[1].ticklabel_format(style='plain', axis='x')\n",
    "axs[2].ticklabel_format(style='plain', axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1364b",
   "metadata": {},
   "source": [
    "We can see some outliers here as well which we will deal with in the next exercise.\n",
    "\n",
    "### Subscribed power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5732da",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = client_df[['id', 'pow_max', 'churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, figsize=(18, 10))\n",
    "plot_distribution(power, 'pow_max', axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9df406",
   "metadata": {},
   "source": [
    "### Other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104843ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "others = client_df[['id', 'nb_prod_act', 'num_years_antig', 'origin_up', 'churn']]\n",
    "products = others.groupby([others[\"nb_prod_act\"],others[\"churn\"]])[\"id\"].count().unstack(level=1)\n",
    "products_percentage = (products.div(products.sum(axis=1), axis=0)*100).sort_values(by=[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71567b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars(products_percentage, \"Number of products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_antig = others.groupby([others[\"num_years_antig\"],others[\"churn\"]])[\"id\"].count().unstack(level=1)\n",
    "years_antig_percentage = (years_antig.div(years_antig.sum(axis=1), axis=0)*100)\n",
    "plot_stacked_bars(years_antig_percentage, \"Number years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = others.groupby([others[\"origin_up\"],others[\"churn\"]])[\"id\"].count().unstack(level=1)\n",
    "origin_percentage = (origin.div(origin.sum(axis=1), axis=0)*100)\n",
    "plot_stacked_bars(origin_percentage, \"Origin contract/offer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd51fb",
   "metadata": {},
   "source": [
    "## 5. Hypothesis investigation\n",
    "\n",
    "Now that we have explored the data, it's time to investigate whether price sensitivity has some influence on churn. First we need to define exactly what is price sensitivity.\n",
    "\n",
    "    > Since we have the consumption data for each of the companies for the year of 2015, we will create new features to measure \"price sensitivity\" using the average of the year, the last 6 months and the last 3 months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date columns to datetime type\n",
    "client_df[\"date_activ\"] = pd.to_datetime(client_df[\"date_activ\"], format='%Y-%m-%d')\n",
    "client_df[\"date_end\"] = pd.to_datetime(client_df[\"date_end\"], format='%Y-%m-%d')\n",
    "client_df[\"date_modif_prod\"] = pd.to_datetime(client_df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
    "client_df[\"date_renewal\"] = pd.to_datetime(client_df[\"date_renewal\"], format='%Y-%m-%d')\n",
    "price_df['price_date'] = pd.to_datetime(price_df['price_date'], format='%Y-%m-%d')\n",
    "\n",
    "# Create mean average data\n",
    "mean_year = price_df.groupby(['id']).mean().reset_index()\n",
    "mean_6m = price_df[price_df['price_date'] > '2015-06-01'].groupby(['id']).mean().reset_index()\n",
    "mean_3m = price_df[price_df['price_date'] > '2015-10-01'].groupby(['id']).mean().reset_index()\n",
    "\n",
    "# Comnbine into single dataframe\n",
    "mean_year = mean_year.rename(\n",
    "    index=str, \n",
    "    columns={\n",
    "        \"price_p1_var\": \"mean_year_price_p1_var\",\n",
    "        \"price_p2_var\": \"mean_year_price_p2_var\",\n",
    "        \"price_p3_var\": \"mean_year_price_p3_var\",\n",
    "        \"price_p1_fix\": \"mean_year_price_p1_fix\",\n",
    "        \"price_p2_fix\": \"mean_year_price_p2_fix\",\n",
    "        \"price_p3_fix\": \"mean_year_price_p3_fix\"\n",
    "    }\n",
    ")\n",
    "\n",
    "mean_year[\"mean_year_price_p1\"] = mean_year[\"mean_year_price_p1_var\"] + mean_year[\"mean_year_price_p1_fix\"]\n",
    "mean_year[\"mean_year_price_p2\"] = mean_year[\"mean_year_price_p2_var\"] + mean_year[\"mean_year_price_p2_fix\"]\n",
    "mean_year[\"mean_year_price_p3\"] = mean_year[\"mean_year_price_p3_var\"] + mean_year[\"mean_year_price_p3_fix\"]\n",
    "\n",
    "mean_6m = mean_6m.rename(\n",
    "    index=str, \n",
    "    columns={\n",
    "        \"price_p1_var\": \"mean_6m_price_p1_var\",\n",
    "        \"price_p2_var\": \"mean_6m_price_p2_var\",\n",
    "        \"price_p3_var\": \"mean_6m_price_p3_var\",\n",
    "        \"price_p1_fix\": \"mean_6m_price_p1_fix\",\n",
    "        \"price_p2_fix\": \"mean_6m_price_p2_fix\",\n",
    "        \"price_p3_fix\": \"mean_6m_price_p3_fix\"\n",
    "    }\n",
    ")\n",
    "mean_6m[\"mean_6m_price_p1\"] = mean_6m[\"mean_6m_price_p1_var\"] + mean_6m[\"mean_6m_price_p1_fix\"]\n",
    "mean_6m[\"mean_6m_price_p2\"] = mean_6m[\"mean_6m_price_p2_var\"] + mean_6m[\"mean_6m_price_p2_fix\"]\n",
    "mean_6m[\"mean_6m_price_p3\"] = mean_6m[\"mean_6m_price_p3_var\"] + mean_6m[\"mean_6m_price_p3_fix\"]\n",
    "\n",
    "mean_3m = mean_3m.rename(\n",
    "    index=str, \n",
    "    columns={\n",
    "        \"price_p1_var\": \"mean_3m_price_p1_var\",\n",
    "        \"price_p2_var\": \"mean_3m_price_p2_var\",\n",
    "        \"price_p3_var\": \"mean_3m_price_p3_var\",\n",
    "        \"price_p1_fix\": \"mean_3m_price_p1_fix\",\n",
    "        \"price_p2_fix\": \"mean_3m_price_p2_fix\",\n",
    "        \"price_p3_fix\": \"mean_3m_price_p3_fix\"\n",
    "    }\n",
    ")\n",
    "mean_3m[\"mean_3m_price_p1\"] = mean_3m[\"mean_3m_price_p1_var\"] + mean_3m[\"mean_3m_price_p1_fix\"]\n",
    "mean_3m[\"mean_3m_price_p2\"] = mean_3m[\"mean_3m_price_p2_var\"] + mean_3m[\"mean_3m_price_p2_fix\"]\n",
    "mean_3m[\"mean_3m_price_p3\"] = mean_3m[\"mean_3m_price_p3_var\"] + mean_3m[\"mean_3m_price_p3_fix\"]\n",
    "\n",
    "# Merge into 1 dataframe\n",
    "price_features = pd.merge(mean_year, mean_6m, on='id')\n",
    "price_features = pd.merge(price_features, mean_3m, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4f02d",
   "metadata": {},
   "source": [
    "Now lets merge in the churn data and see whether price sensitivity has any correlation with churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e879a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_analysis = pd.merge(price_features, client_df[['id', 'churn']], on='id')\n",
    "price_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = price_analysis.corr()\n",
    "# Plot correlation\n",
    "plt.figure(figsize=(20,18))\n",
    "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot = True, annot_kws={'size':10})\n",
    "# Axis ticks size\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04544d3d",
   "metadata": {},
   "source": [
    "From the correlation plot, it shows a higher magnitude of correlation between other price sensitivity variables, however overall the correlation with churn is very low. This indicates that there is a weak linear relationship between price sensitity and churn. This suggests that for price sensivity to be a major driver for predicting churn, we may need to engineer the feature differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(client_df.drop(columns=['churn']), price_analysis, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6110877",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('clean_data_after_eda.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "152bf6e7dc8ee53edb5af21dc1a8faeab7f134840808a94079ed98d91ece7e0c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
